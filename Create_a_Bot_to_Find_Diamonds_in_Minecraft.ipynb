{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuB/D5PNN3to37Jj/6os2P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mlabonne/how-to-data-science/blob/main/Create_a_Bot_to_Find_Diamonds_in_Minecraft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Bot to Find Diamonds in Minecraft\n",
        "\n",
        "❤️ Created by [@maximelabonne](https://twitter.com/maximelabonne).\n",
        "\n",
        "Companion notebook to execute the code from the following article: https://mlabonne.github.io/blog/minecraft/"
      ],
      "metadata": {
        "id": "FtEL4IzOLF_s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ePZ3c_ULByP"
      },
      "outputs": [],
      "source": [
        "# # Install JDK, OpenGL, etc.\n",
        "!sudo add-apt-repository -y ppa:openjdk-r/ppa > /dev/null 2>&1\n",
        "!sudo apt purge openjdk-* > /dev/null 2>&1\n",
        "!sudo apt install openjdk-8-jdk xvfb xserver-xephyr vnc4server python-opengl ffmpeg > /dev/null 2>&1\n",
        "\n",
        "# # Install MineRL, the virtual display, and a video renderer\n",
        "!pip install -q -U minerl pyvirtualdisplay colabgymrender imageio==2.4.1\n",
        "\n",
        "# RL environment\n",
        "import gym\n",
        "import minerl\n",
        "\n",
        "# Visualization\n",
        "from colabgymrender.recorder import Recorder\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Others\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import logging\n",
        "logging.disable(logging.ERROR)\n",
        "\n",
        "# Create virtual display\n",
        "display = Display(visible=0, size=(400, 300))\n",
        "display.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## I. Scripted bot\n",
        "\n",
        "Let's try simple actions: forward (5 steps) and wait (40 steps)."
      ],
      "metadata": {
        "id": "xnQH8chLLUua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the sequence of actions\n",
        "script = ['forward'] * 5 + [''] * 40\n",
        "\n",
        "env = gym.make('MineRLObtainDiamond-v0')\n",
        "env = Recorder(env, './video', fps=60)\n",
        "env.seed(21)\n",
        "obs = env.reset()\n",
        "\n",
        "for action in script:\n",
        "    # Get the action space (dict of possible actions)\n",
        "    action_space = env.action_space.noop()\n",
        "\n",
        "    # Activate the selected action in the script\n",
        "    action_space[action] = 1\n",
        "\n",
        "    # Update the environment with the new action space\n",
        "    obs, reward, done, _ = env.step(action_space)\n",
        "\n",
        "env.release()\n",
        "env.play()"
      ],
      "metadata": {
        "id": "p876sjl0LUUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can create more complex sequence of actions thanks to the `str_to_act` function. Let's chop the tree this time."
      ],
      "metadata": {
        "id": "opEVXbxELnou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code from https://github.com/KarolisRam/MineRL2021-Intro-baselines\n",
        "def str_to_act(env, actions):\n",
        "    action_space = env.action_space.noop()\n",
        "    for action in actions.split():\n",
        "        if ':' in action:\n",
        "            k, v = action.split(':')\n",
        "            if k == 'camera':\n",
        "                action_space[k] = eval(v)\n",
        "            else:\n",
        "                action_space[k] = v\n",
        "        else:\n",
        "            action_space[action] = 1\n",
        "    return action_space\n",
        "\n",
        "script = []\n",
        "script += [''] * 20 \n",
        "script += ['forward'] * 5\n",
        "script += ['attack'] * 61\n",
        "script += ['camera:[-10,0]'] * 7  # Look up\n",
        "script += ['attack'] * 240\n",
        "script += ['jump']\n",
        "script += ['forward'] * 10        # Jump forward\n",
        "script += ['camera:[-10,0]'] * 2  # Look up\n",
        "script += ['attack'] * 150\n",
        "script += ['camera:[10,0]'] * 7   # Look down\n",
        "script += [''] * 40"
      ],
      "metadata": {
        "id": "ypNw7fePLd06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('MineRLObtainDiamond-v0')\n",
        "env = Recorder(env, './video', fps=60)\n",
        "env.seed(21)\n",
        "obs = env.reset()\n",
        " \n",
        "for action in tqdm(script):\n",
        "    obs, reward, done, _ = env.step(str_to_act(env, action))\n",
        "\n",
        "env.release()\n",
        "env.play()"
      ],
      "metadata": {
        "id": "krTD4CUDLdta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/3A2P0lQs2c0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "FnrVKBK_XFo0",
        "outputId": "cee7c24e-1e33-47bb-b529-92b3dd64c123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/3A2P0lQs2c0\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Imitation Learning\n",
        "\n",
        "A more flexible solution consists of training an agent to chop wood. In this example, we choose an imitation learning framework (supervised learning with a dataset of videos)."
      ],
      "metadata": {
        "id": "Rp4vGDpzL18L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_shape, output_dim):\n",
        "        super().__init__()\n",
        "        n_input_channels = input_shape[0]\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(n_input_channels, 32, kernel_size=8, stride=4),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, observations):\n",
        "        return self.cnn(observations)\n",
        "\n",
        "def dataset_action_batch_to_actions(dataset_actions, camera_margin=5):\n",
        "    camera_actions = dataset_actions[\"camera\"].squeeze()\n",
        "    attack_actions = dataset_actions[\"attack\"].squeeze()\n",
        "    forward_actions = dataset_actions[\"forward\"].squeeze()\n",
        "    jump_actions = dataset_actions[\"jump\"].squeeze()\n",
        "    batch_size = len(camera_actions)\n",
        "    actions = np.zeros((batch_size,), dtype=int)\n",
        "\n",
        "    for i in range(len(camera_actions)):\n",
        "        if camera_actions[i][0] < -camera_margin:\n",
        "            actions[i] = 3\n",
        "        elif camera_actions[i][0] > camera_margin:\n",
        "            actions[i] = 4\n",
        "        elif camera_actions[i][1] > camera_margin:\n",
        "            actions[i] = 5\n",
        "        elif camera_actions[i][1] < -camera_margin:\n",
        "            actions[i] = 6\n",
        "        elif forward_actions[i] == 1:\n",
        "            if jump_actions[i] == 1:\n",
        "                actions[i] = 2\n",
        "            else:\n",
        "                actions[i] = 1\n",
        "        elif attack_actions[i] == 1:\n",
        "            actions[i] = 0\n",
        "        else:\n",
        "            actions[i] = -1\n",
        "    return actions\n",
        "\n",
        "class ActionShaping(gym.ActionWrapper):\n",
        "    def __init__(self, env, camera_angle=10):\n",
        "        super().__init__(env)\n",
        "        self.camera_angle = camera_angle\n",
        "        self._actions = [\n",
        "            [('attack', 1)],\n",
        "            [('forward', 1)],\n",
        "            [('jump', 1)],\n",
        "            [('camera', [-self.camera_angle, 0])],\n",
        "            [('camera', [self.camera_angle, 0])],\n",
        "            [('camera', [0, self.camera_angle])],\n",
        "            [('camera', [0, -self.camera_angle])],\n",
        "        ]\n",
        "        self.actions = []\n",
        "        for actions in self._actions:\n",
        "            act = self.env.action_space.noop()\n",
        "            for a, v in actions:\n",
        "                act[a] = v\n",
        "                act['attack'] = 1\n",
        "            self.actions.append(act)\n",
        "        self.action_space = gym.spaces.Discrete(len(self.actions))\n",
        "\n",
        "    def action(self, action):\n",
        "        return self.actions[action]"
      ],
      "metadata": {
        "id": "N3yChMnSL2MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Get data\n",
        "minerl.data.download(directory='data', environment='MineRLTreechop-v0')\n",
        "data = minerl.data.make(\"MineRLTreechop-v0\", data_dir='data', num_workers=2)\n",
        "\n",
        "# Model\n",
        "model = CNN((3, 64, 64), 7).cuda()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "step = 0\n",
        "losses = []\n",
        "for state, action, _, _, _ \\\n",
        "          in tqdm(data.batch_iter(num_epochs=6, batch_size=32, seq_len=1)):\n",
        "    # Get pov observations\n",
        "    obs = state['pov'].squeeze().astype(np.float32)\n",
        "    # Transpose and normalize\n",
        "    obs = obs.transpose(0, 3, 1, 2) / 255.0\n",
        "\n",
        "    # Translate batch of actions for the ActionShaping wrapper\n",
        "    actions = dataset_action_batch_to_actions(action)\n",
        "\n",
        "    # Remove samples with no corresponding action\n",
        "    mask = actions != -1\n",
        "    obs = obs[mask]\n",
        "    actions = actions[mask]\n",
        "\n",
        "    # Update weights with backprop\n",
        "    logits = model(torch.from_numpy(obs).float().cuda())\n",
        "    loss = criterion(logits, torch.from_numpy(actions).long().cuda())\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Print loss\n",
        "    step += 1\n",
        "    losses.append(loss.item())\n",
        "    if (step % 2000) == 0:\n",
        "        mean_loss = sum(losses) / len(losses)\n",
        "        tqdm.write(f'Step {step:>5} | Training loss = {mean_loss:.3f}')\n",
        "        losses.clear()\n",
        "\n",
        "torch.save(model.state_dict(), 'model.pth')\n",
        "del data"
      ],
      "metadata": {
        "id": "yVcri_BmMBat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the result of the training:"
      ],
      "metadata": {
        "id": "RP19ypy0MoJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN((3, 64, 64), 7).cuda()\n",
        "model.load_state_dict(torch.load('model.pth'))\n",
        "\n",
        "env = gym.make('MineRLObtainDiamond-v0')\n",
        "env1 = Recorder(env, './video', fps=60)\n",
        "env = ActionShaping(env1)\n",
        "\n",
        "action_list = np.arange(env.action_space.n)\n",
        "\n",
        "obs = env.reset()\n",
        "\n",
        "for step in tqdm(range(1000)):\n",
        "    # Get input in the correct format\n",
        "    obs = torch.from_numpy(obs['pov'].transpose(2, 0, 1)[None].astype(np.float32) / 255).cuda()\n",
        "    # Turn logits into probabilities\n",
        "    probabilities = torch.softmax(model(obs), dim=1)[0].detach().cpu().numpy()\n",
        "    # Sample action according to the probabilities\n",
        "    action = np.random.choice(action_list, p=probabilities)\n",
        "\n",
        "    obs, reward, _, _ = env.step(action)\n",
        "\n",
        "env1.release()\n",
        "env1.play()"
      ],
      "metadata": {
        "id": "DVP0f8QhMh_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/umvrmQ_MYSI\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "DqMZ4_XlW6L1",
        "outputId": "d6a48496-7b05-45b8-a25a-7fd3ef92c7fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/umvrmQ_MYSI\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## III. Script + Imitation Learning"
      ],
      "metadata": {
        "id": "kbnFuzmQMq0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Craft 4 planks, 2 sticks, 2 crafting tables, and place it\n",
        "script = []\n",
        "script += ['craft:planks'] * 6\n",
        "script += ['craft:stick'] * 2\n",
        "script += ['craft:crafting_table'] * 2\n",
        "script += ['camera:[10,0]'] * 18\n",
        "script += ['attack'] * 20\n",
        "script += [''] * 10\n",
        "script += ['jump']\n",
        "script += [''] * 5\n",
        "script += ['place:crafting_table']\n",
        "script += [''] * 10\n",
        "\n",
        "# Craft a wooden pickaxe and equip it\n",
        "script += ['camera:[-1,0]']\n",
        "script += ['nearbyCraft:wooden_pickaxe']\n",
        "script += ['camera:[1,0]']\n",
        "script += [''] * 10\n",
        "script += ['equip:wooden_pickaxe']\n",
        "script += [''] * 10\n",
        "\n",
        "# Dig stone\n",
        "script += ['attack'] * 500\n",
        "\n",
        "# Craft stone pickaxe\n",
        "script += [''] * 10\n",
        "script += ['jump']\n",
        "script += [''] * 5\n",
        "script += ['place:crafting_table']\n",
        "script += [''] * 10\n",
        "script += ['camera:[-1,0]']\n",
        "script += ['nearbyCraft:stone_pickaxe']\n",
        "script += ['camera:[1,0]']\n",
        "script += [''] * 10\n",
        "script += ['equip:stone_pickaxe']\n",
        "script += [''] * 10"
      ],
      "metadata": {
        "id": "Kz-AdH0fMrC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN((3, 64, 64), 7).cuda()\n",
        "model.load_state_dict(torch.load('model.pth'))\n",
        "\n",
        "env_script = gym.make('MineRLObtainDiamond-v0')\n",
        "env_cnn = Recorder(env_script, './video', fps=60)\n",
        "env_script = ActionShaping(env_cnn)\n",
        "\n",
        "action_list = np.arange(env_script.action_space.n)\n",
        "\n",
        "for _ in range(10):\n",
        "    obs = env_script.reset()\n",
        "    done = False\n",
        "\n",
        "    # 1. Get wood with the CNN\n",
        "    for i in tqdm(range(3000)):\n",
        "        obs = torch.from_numpy(obs['pov'].transpose(2, 0, 1)[None].astype(np.float32) / 255).cuda()\n",
        "        probabilities = torch.softmax(model(obs), dim=1)[0].detach().cpu().numpy()\n",
        "        action = np.random.choice(action_list, p=probabilities)\n",
        "        obs, reward, done, _ = env_script.step(action)\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # 2. Craft stone pickaxe with scripted actions\n",
        "    if not done:\n",
        "        for action in tqdm(script):\n",
        "            obs, reward, done, _ = env_cnn.step(str_to_act(env_cnn, action))\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "    print(obs[\"inventory\"])\n",
        "    env_cnn.release()\n",
        "    env_cnn.play()"
      ],
      "metadata": {
        "id": "gZjFL5BwM0Uz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final result:"
      ],
      "metadata": {
        "id": "siNlN9tzNEm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/7LnjA7Bxf6A\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "b4rin3aCNG5T",
        "outputId": "f217ce91-2334-4555-b957-77abbf9aa30c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/7LnjA7Bxf6A\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}